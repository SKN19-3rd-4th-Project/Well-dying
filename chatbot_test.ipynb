{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb4d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\vectordb\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c207cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_HOST = \"https://funeral-index-wb03sz2.svc.aped-4627-b74a.pinecone.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b530e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback # ìƒì„¸ ì—ëŸ¬ í™•ì¸ì„ ìœ„í•´ ì¶”ê°€\n",
    "import os\n",
    "\n",
    "@tool\n",
    "def search_columbarium(query: str, region: str = None):\n",
    "    \"\"\"\n",
    "    ë´‰ì•ˆë‹¹ ë˜ëŠ” ë‚©ê³¨ë‹¹ì„ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        query (str): ê²€ìƒ‰í•  ì§ˆë¬¸ ë‚´ìš© (ì˜ˆ: \"ì‹œì„¤ ì¢‹ì€ ë´‰ì•ˆë‹¹\")\n",
    "        region (str, optional): ì‚¬ìš©ìê°€ íŠ¹ì • ì§€ì—­ì„ ì–¸ê¸‰í•œ ê²½ìš° í•´ë‹¹ ì§€ì—­ëª….\n",
    "                                ë°ì´í„°ë² ì´ìŠ¤ì˜ ì§€ì—­ëª…ì€ 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì¶©ì²­ë¶ë„' ë“± ê´‘ì—­ìì¹˜ë‹¨ì²´ ëª…ì¹­ì…ë‹ˆë‹¤.\n",
    "                                ì‚¬ìš©ìê°€ 'ë¶€ì‚°'ì´ë¼ê³  í•˜ë©´ 'ë¶€ì‚°ê´‘ì—­ì‹œ'ë¡œ, 'ì¶©ë¶'ì´ë¼ê³  í•˜ë©´ 'ì¶©ì²­ë¶ë„'ë¡œ ë³€í™˜í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: {query}, ì§€ì—­í•„í„°: {region}\")\n",
    "    \n",
    "    # 1. ì—°ê²° ì„¤ì •\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "    index = pc.Index(host=os.environ.get(\"PINECONE_INDEX_HOST\"))\n",
    "    vectorstore = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "    \n",
    "    # 2. ë©”íƒ€ë°ì´í„° í•„í„° ìƒì„±\n",
    "    # Pinecone í•„í„° ë¬¸ë²•: {'meta_key': {'$eq': 'value'}}\n",
    "    filter_dict = {}\n",
    "    if region:\n",
    "        filter_dict[\"region\"] = {\"$eq\": region}\n",
    "        print(f\"âœ… ì§€ì—­ í•„í„° ì ìš©ë¨: {region}\")\n",
    "    \n",
    "    # 3. í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "    try:\n",
    "        results = vectorstore.similarity_search(\n",
    "            query, \n",
    "            k=3,\n",
    "            filter=filter_dict  # ì—¬ê¸°ì— í•„í„°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "    # 4. ê²°ê³¼ ë°˜í™˜\n",
    "    if not results:\n",
    "        return \"í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì‹œì„¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    formatted_results = \"\"\n",
    "    for i, doc in enumerate(results):\n",
    "        formatted_results += f\"\\n[ê²°ê³¼ {i+1}]\\n\"\n",
    "        formatted_results += f\"ì´ë¦„: {doc.metadata.get('name')}\\n\"\n",
    "        formatted_results += f\"ì§€ì—­: {doc.metadata.get('region')} {doc.metadata.get('location')}\\n\"\n",
    "        formatted_results += f\"ì£¼ì†Œ: {doc.metadata.get('address')}\\n\"\n",
    "        formatted_results += f\"ì „í™”ë²ˆí˜¸: {doc.metadata.get('phone')}\\n\"\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0128e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangGraph ìƒíƒœ ë° ë…¸ë“œ ì •ì˜\n",
    "tools = [search_columbarium]\n",
    "\n",
    "# LLM ëª¨ë¸ ë¡œë“œ ë° ë„êµ¬ ë°”ì¸ë”©\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# ê·¸ë˜í”„ì˜ State ì •ì˜ (ëŒ€í™” ê¸°ë¡ ìœ ì§€)\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    # í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜´\n",
    "    current_messages = state['messages']\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    system_prompt = SystemMessage(content=\"\"\"\n",
    "    ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì‚¬ë ¤ ê¹Šì€ 'ì¥ì‚¬ ì •ë³´ ì•ˆë‚´ ë„ìš°ë¯¸'ì…ë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ìê°€ ì¥ë¡€ì‹ì¥, ë´‰ì•ˆë‹¹, ë‚©ê³¨ë‹¹ ë“±ì˜ ì •ë³´ë¥¼ ë¬»ê±°ë‚˜, ì£½ìŒ/ì„ì¢…/ë¹ˆì†Œ/ì¡°ë¬¸ ë“±ê³¼ ê´€ë ¨ëœ ìƒí™©ì„ ì•”ì‹œí•˜ë©´ \n",
    "    ë°˜ë“œì‹œ 'search_columbarium' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ ì¥ì†Œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.\n",
    "    \n",
    "    ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì§€ì—­ì„ ë§í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ë¨¼ì € ì–´ëŠ ì§€ì—­ì„ ì°¾ëŠ”ì§€ ì •ì¤‘í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.\n",
    "    ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ì œê³µí•  ë•ŒëŠ” ìœ„ë¡œì˜ ë§ê³¼ í•¨ê»˜ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”.\n",
    "    \"\"\")\n",
    "\n",
    "    # ëŒ€í™” ê¸°ë¡ ë§¨ ì•ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´, ì´ë²ˆ í„´(invoke)ì—ë§Œ ì„ì‹œë¡œ ë¶™ì—¬ì„œ ë³´ëƒ„\n",
    "    # (stateì— ì˜êµ¬ ì €ì¥í•˜ì§€ ì•ŠìŒìœ¼ë¡œì¨ ì¤‘ë³µ ë°©ì§€)\n",
    "    if not isinstance(current_messages[0], SystemMessage):\n",
    "        messages_to_send = [system_prompt] + current_messages\n",
    "    else:\n",
    "        messages_to_send = current_messages\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = llm_with_tools.invoke(messages_to_send)\n",
    "    print(\"response:\", response)\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ì‘ë‹µë§Œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ ë°˜í™˜ (add_messagesê°€ ì•Œì•„ì„œ ê¸°ì¡´ ê¸°ë¡ ë’¤ì— ë¶™ì—¬ì¤Œ)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# [Node 2] ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# [Edge] ì¡°ê±´ë¶€ ì—£ì§€: ë„êµ¬ë¥¼ ì“¸ì§€, ë‹µë³€ì„ ëë‚¼ì§€ ê²°ì •\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    print(f\"Tool Calls ì¡´ì¬ ì—¬ë¶€: {last_message.tool_calls}\")\n",
    "    \n",
    "    # LLMì´ ë„êµ¬ í˜¸ì¶œì„ ìš”ì²­í–ˆëŠ”ì§€ í™•ì¸\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b00d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ê·¸ë˜í”„ êµ¬ì„± (Workflow)\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "workflow.set_entry_point(\"agent\") # ì‹œì‘ì \n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\") # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì—ì´ì „íŠ¸ë¡œ ë³µê·€ (ê²°ê³¼ í•´ì„)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050de4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "def chat(user_input):\n",
    "    print(f\"\\nì‚¬ìš©ì: {user_input}\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "    \n",
    "    # ê·¸ë˜í”„ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê³¼ì • í™•ì¸ ê°€ëŠ¥)\n",
    "    for event in app.stream(inputs):\n",
    "        for key, value in event.items():\n",
    "            if key == \"agent\":\n",
    "                msg = value[\"messages\"][0]\n",
    "                print(f\"Agent ìƒê°: {msg.content}\") # ë””ë²„ê¹…ìš©\n",
    "            elif key == \"tools\":\n",
    "                # print(f\"Tool ì‹¤í–‰ ê²°ê³¼...\") # ë””ë²„ê¹…ìš©\n",
    "                pass\n",
    "    \n",
    "    # ìµœì¢… ì‘ë‹µ ì¶œë ¥\n",
    "    final_response = value[\"messages\"][0].content\n",
    "    print(f\"ì±—ë´‡: {final_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20542386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì‚¬ìš©ì: ì„œìš¸ì— ìˆëŠ” ë´‰ì•ˆë‹¹ì„ ì•Œë ¤ì¤˜.\n",
      "response: content='' additional_kwargs={'tool_calls': [{'id': 'call_q3H9oHZeMKWE0MmuDRyhcWnr', 'function': {'arguments': '{\"query\":\"ë´‰ì•ˆë‹¹\",\"region\":\"ì„œìš¸íŠ¹ë³„ì‹œ\"}', 'name': 'search_columbarium'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 319, 'total_tokens': 344, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_01ea9a21fc', 'id': 'chatcmpl-CeGkrwvrMoJrPxxjq5uAmwsDbH2sg', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--c2362a5f-aacb-4d19-881c-1c7aed616208-0' tool_calls=[{'name': 'search_columbarium', 'args': {'query': 'ë´‰ì•ˆë‹¹', 'region': 'ì„œìš¸íŠ¹ë³„ì‹œ'}, 'id': 'call_q3H9oHZeMKWE0MmuDRyhcWnr', 'type': 'tool_call'}] usage_metadata={'input_tokens': 319, 'output_tokens': 25, 'total_tokens': 344, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Tool Calls ì¡´ì¬ ì—¬ë¶€: [{'name': 'search_columbarium', 'args': {'query': 'ë´‰ì•ˆë‹¹', 'region': 'ì„œìš¸íŠ¹ë³„ì‹œ'}, 'id': 'call_q3H9oHZeMKWE0MmuDRyhcWnr', 'type': 'tool_call'}]\n",
      "Agent ìƒê°: \n",
      "ğŸ” ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: ë´‰ì•ˆë‹¹, ì§€ì—­í•„í„°: ì„œìš¸íŠ¹ë³„ì‹œ\n",
      "âœ… ì§€ì—­ í•„í„° ì ìš©ë¨: ì„œìš¸íŠ¹ë³„ì‹œ\n",
      "response: content='ì„œìš¸ì—ì„œ ë´‰ì•ˆë‹¹ì„ ì°¾ê³  ê³„ì‹œëŠ”êµ°ìš”. ë§ˆìŒì´ ë¬´ê±°ìš°ì‹¤ í…ë°, ì¡°ê¸ˆì´ë‚˜ë§ˆ ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤. ì•„ë˜ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì— ìœ„ì¹˜í•œ ë´‰ì•ˆë‹¹ ì •ë³´ì…ë‹ˆë‹¤:\\n\\n1. **ì •ê°ì‚¬ ë´‰ì•ˆë‹¹**\\n   - **ì§€ì—­:** ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬\\n   - **ì „í™”ë²ˆí˜¸:** 02-584-1983\\n\\n2. **ë‹¬ë§ˆì‚¬ë´‰ì•ˆë‹¹**\\n   - **ì§€ì—­:** ì„œìš¸íŠ¹ë³„ì‹œ ë™ì‘êµ¬\\n   - **ì „í™”ë²ˆí˜¸:** 02-822-8771\\n\\ní•„ìš”í•˜ì‹  ì •ë³´ê°€ ë„ì›€ì´ ë˜ê¸¸ ë°”ë¼ë©°, ì–¸ì œë“ ì§€ ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 478, 'total_tokens': 623, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_01ea9a21fc', 'id': 'chatcmpl-CeGkwu5EC6Ja7vidCZNTf1YYNHDFW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--12761e8e-11b9-498e-acf2-fd0b0611a49b-0' usage_metadata={'input_tokens': 478, 'output_tokens': 145, 'total_tokens': 623, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Tool Calls ì¡´ì¬ ì—¬ë¶€: []\n",
      "Agent ìƒê°: ì„œìš¸ì—ì„œ ë´‰ì•ˆë‹¹ì„ ì°¾ê³  ê³„ì‹œëŠ”êµ°ìš”. ë§ˆìŒì´ ë¬´ê±°ìš°ì‹¤ í…ë°, ì¡°ê¸ˆì´ë‚˜ë§ˆ ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤. ì•„ë˜ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì— ìœ„ì¹˜í•œ ë´‰ì•ˆë‹¹ ì •ë³´ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **ì •ê°ì‚¬ ë´‰ì•ˆë‹¹**\n",
      "   - **ì§€ì—­:** ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬\n",
      "   - **ì „í™”ë²ˆí˜¸:** 02-584-1983\n",
      "\n",
      "2. **ë‹¬ë§ˆì‚¬ë´‰ì•ˆë‹¹**\n",
      "   - **ì§€ì—­:** ì„œìš¸íŠ¹ë³„ì‹œ ë™ì‘êµ¬\n",
      "   - **ì „í™”ë²ˆí˜¸:** 02-822-8771\n",
      "\n",
      "í•„ìš”í•˜ì‹  ì •ë³´ê°€ ë„ì›€ì´ ë˜ê¸¸ ë°”ë¼ë©°, ì–¸ì œë“ ì§€ ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "ì±—ë´‡: ì„œìš¸ì—ì„œ ë´‰ì•ˆë‹¹ì„ ì°¾ê³  ê³„ì‹œëŠ”êµ°ìš”. ë§ˆìŒì´ ë¬´ê±°ìš°ì‹¤ í…ë°, ì¡°ê¸ˆì´ë‚˜ë§ˆ ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤. ì•„ë˜ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì— ìœ„ì¹˜í•œ ë´‰ì•ˆë‹¹ ì •ë³´ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **ì •ê°ì‚¬ ë´‰ì•ˆë‹¹**\n",
      "   - **ì§€ì—­:** ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬\n",
      "   - **ì „í™”ë²ˆí˜¸:** 02-584-1983\n",
      "\n",
      "2. **ë‹¬ë§ˆì‚¬ë´‰ì•ˆë‹¹**\n",
      "   - **ì§€ì—­:** ì„œìš¸íŠ¹ë³„ì‹œ ë™ì‘êµ¬\n",
      "   - **ì „í™”ë²ˆí˜¸:** 02-822-8771\n",
      "\n",
      "í•„ìš”í•˜ì‹  ì •ë³´ê°€ ë„ì›€ì´ ë˜ê¸¸ ë°”ë¼ë©°, ì–¸ì œë“ ì§€ ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ì¼€ì´ìŠ¤ 1: ì§ì ‘ì ì¸ ìš”ì²­\n",
    "chat(\"ì„œìš¸ì— ìˆëŠ” ë´‰ì•ˆë‹¹ì„ ì•Œë ¤ì¤˜.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabc0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # ì¼€ì´ìŠ¤ 2: ì•”ì‹œì ì¸ ìƒí™© (ë„êµ¬ í˜¸ì¶œ ì „ ì§€ì—­ í™•ì¸ ìœ ë„ ì˜ˆìƒ)\n",
    "# chat(\"ê°‘ìê¸° ì•„ë²„ì§€ê°€ ëŒì•„ê°€ì…¨ì–´.. ì–´ë–¡í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë„¤.\")\n",
    "\n",
    "# # ì¼€ì´ìŠ¤ 3: ì•”ì‹œì  ìƒí™© + ì§€ì—­ í¬í•¨\n",
    "# chat(\"ì§€ê¸ˆ ë¶€ì‚° í•´ìš´ëŒ€ ìª½ì¸ë°, ê¸‰í•˜ê²Œ ë¹ˆì†Œë¥¼ ì•Œì•„ë´ì•¼ í•´.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e39e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat(\"ë¶€ì‚°ê´‘ì—­ì‹œì— ìˆëŠ” ë´‰ì•ˆë‹¹ì„ ì•Œë ¤ì¤˜\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
