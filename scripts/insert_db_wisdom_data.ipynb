{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff344f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ pinecone 설치 완료\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# pinecone 재설치\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pinecone\"])\n",
    "\n",
    "print(\"✓ pinecone 설치 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31678584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# pinecone 강제 새로고침\n",
    "if 'pinecone' in sys.modules:\n",
    "    del sys.modules['pinecone']\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ad3084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"YOUR_OPENAI_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"YOUR_PINECONE_KEY\")\n",
    "INDEX_NAME = \"welldying-wisdom\"\n",
    "\n",
    "PDF_FILES = [\n",
    "    \"ALTIIA-3.1.pdf\",\n",
    "    \"Death_Immortality_and_Meaning_in_Life_Precis_and_F.pdf\"\n",
    "]\n",
    "\n",
    "TARGET_URLS = [\n",
    "    \"https://www.apa.org/topics/aging-older-adults/end-of-life-decisions\",\n",
    "    \"https://plato.stanford.edu/entries/death/\",\n",
    "    \"https://gadfly.igc.org/papers/pr/pipr.htm\"\n",
    "]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48cedeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(filepath: str) -> str:\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "        logger.info(f\"[PDF] 추출 완료: {filepath} ({len(text)}자)\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[PDF] 에러 발생 ({filepath}): {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab1edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_url(url: str) -> str:\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 불필요한 태그 제거 (스크립트, 스타일, 네비게이션 등)\n",
    "        for script in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\"]):\n",
    "            script.decompose()\n",
    "            \n",
    "        # 본문 텍스트 추출\n",
    "        text = soup.get_text(separator='\\n')\n",
    "        \n",
    "        # 공백 정리\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        clean_text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "        logger.info(f\"[URL] 크롤링 완료: {url} ({len(clean_text)}자)\")\n",
    "        return clean_text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[URL] 에러 발생 ({url}): {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222d602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_upload(texts: List[Dict[str, str]]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    \n",
    "    # 인덱스 확인 (없으면 생성)\n",
    "    if INDEX_NAME not in pc.list_indexes().names():\n",
    "        logger.info(f\"인덱스 '{INDEX_NAME}' 생성 중...\")\n",
    "        from pinecone import ServerlessSpec\n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=1536, \n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "        )\n",
    "    \n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    documents_to_upload = []\n",
    "    \n",
    "    # 청킹 작업\n",
    "    for item in texts:\n",
    "        source_name = item['source']\n",
    "        raw_text = item['text']\n",
    "        \n",
    "        chunks = text_splitter.split_text(raw_text)\n",
    "        logger.info(f\"Processing {source_name}: {len(chunks)} chunks generated.\")\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            documents_to_upload.append({\n",
    "                \"id\": str(uuid4()),\n",
    "                \"text\": chunk,\n",
    "                \"source\": source_name,\n",
    "                \"type\": \"wisdom\" # search_welldying_wisdom_tool이 검색할 태그\n",
    "            })\n",
    "            \n",
    "    # 임베딩 및 업로드 (Batch 처리)\n",
    "    batch_size = 100\n",
    "    total_docs = len(documents_to_upload)\n",
    "    \n",
    "    logger.info(f\"총 {total_docs}개의 청크\")\n",
    "    \n",
    "    for i in tqdm(range(0, total_docs, batch_size)):\n",
    "        batch = documents_to_upload[i:i+batch_size]\n",
    "        \n",
    "        # 텍스트 리스트 추출\n",
    "        batch_texts = [doc['text'] for doc in batch]\n",
    "        \n",
    "        # 임베딩 생성\n",
    "        try:\n",
    "            batch_embeddings = embeddings.embed_documents(batch_texts)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"임베딩 생성 중 오류: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # 벡터 데이터 구성\n",
    "        vectors = []\n",
    "        for doc, vector in zip(batch, batch_embeddings):\n",
    "            metadata = {\n",
    "                \"content\": doc['text'], # 검색 시 LLM에게 보여줄 본문\n",
    "                \"source\": doc['source'],\n",
    "                \"type\": doc['type']\n",
    "            }\n",
    "            vectors.append((doc['id'], vector, metadata))\n",
    "            \n",
    "        index.upsert(vectors=vectors)\n",
    "        \n",
    "    logger.info(\"✅ 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8571ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:[PDF] 추출 완료: ALTIIA-3.1.pdf (36748자)\n",
      "INFO:__main__:[PDF] 추출 완료: Death_Immortality_and_Meaning_in_Life_Precis_and_F.pdf (68136자)\n",
      "INFO:__main__:[PDF] 추출 완료: Death_Immortality_and_Meaning_in_Life_Precis_and_F.pdf (68136자)\n",
      "INFO:__main__:[URL] 크롤링 완료: https://www.apa.org/topics/aging-older-adults/end-of-life-decisions (0자)\n",
      "INFO:__main__:[URL] 크롤링 완료: https://www.apa.org/topics/aging-older-adults/end-of-life-decisions (0자)\n",
      "INFO:__main__:[URL] 크롤링 완료: https://plato.stanford.edu/entries/death/ (109233자)\n",
      "INFO:__main__:[URL] 크롤링 완료: https://plato.stanford.edu/entries/death/ (109233자)\n",
      "INFO:__main__:[URL] 크롤링 완료: https://gadfly.igc.org/papers/pr/pipr.htm (67110자)\n",
      "INFO:__main__:[URL] 크롤링 완료: https://gadfly.igc.org/papers/pr/pipr.htm (67110자)\n",
      "INFO:__main__:인덱스 'welldying-wisdom' 생성 중...\n",
      "INFO:__main__:인덱스 'welldying-wisdom' 생성 중...\n",
      "INFO:__main__:Processing ALTIIA-3.1.pdf: 46 chunks generated.\n",
      "INFO:__main__:Processing Death_Immortality_and_Meaning_in_Life_Precis_and_F.pdf: 86 chunks generated.\n",
      "INFO:__main__:Processing https://plato.stanford.edu/entries/death/: 137 chunks generated.\n",
      "INFO:__main__:Processing https://gadfly.igc.org/papers/pr/pipr.htm: 83 chunks generated.\n",
      "INFO:__main__:총 352개의 청크\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:Processing ALTIIA-3.1.pdf: 46 chunks generated.\n",
      "INFO:__main__:Processing Death_Immortality_and_Meaning_in_Life_Precis_and_F.pdf: 86 chunks generated.\n",
      "INFO:__main__:Processing https://plato.stanford.edu/entries/death/: 137 chunks generated.\n",
      "INFO:__main__:Processing https://gadfly.igc.org/papers/pr/pipr.htm: 83 chunks generated.\n",
      "INFO:__main__:총 352개의 청크\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      " 25%|██▌       | 1/4 [00:05<00:15,  5.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 2/4 [00:08<00:07,  3.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      " 75%|███████▌  | 3/4 [00:10<00:03,  3.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.19s/it]\n",
      "INFO:__main__:✅ 완료\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.19s/it]\n",
      "INFO:__main__:✅ 완료\n"
     ]
    }
   ],
   "source": [
    "collected_data = []\n",
    "\n",
    "for pdf in PDF_FILES:\n",
    "    text = extract_text_from_pdf(pdf)\n",
    "    if text:\n",
    "        collected_data.append({\"source\": pdf, \"text\": text})\n",
    "    \n",
    "for url in TARGET_URLS:\n",
    "    text = extract_text_from_url(url)\n",
    "    if text:\n",
    "        collected_data.append({\"source\": url, \"text\": text})\n",
    "        \n",
    "process_and_upload(collected_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
