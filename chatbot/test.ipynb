{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78ec8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vhqhr\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from conversation_engine import ConversationEngine\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe525c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    print(\">>> [í…ŒìŠ¤íŠ¸] ì›°ë‹¤ì‰ ì±—ë´‡ ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\">>> '/toggle'ì„ ì…ë ¥í•˜ë©´ ì±„íŒ… ëª¨ë“œì™€ ì •ë³´ ëª¨ë“œê°€ ì „í™˜ë©ë‹ˆë‹¤.\")\n",
    "    print(\">>> 'ê·¸ë§Œ'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "    engine = ConversationEngine()\n",
    "    user_id = \"sangjunking\"\n",
    "    \n",
    "    # ì´ˆê¸° ëª¨ë“œ ì„¤ì • (ê¸°ë³¸ê°’: chat)\n",
    "    current_mode = \"chat\"\n",
    "    \n",
    "    # ì›°ì»´ ë©”ì‹œì§€ í™•ì¸\n",
    "    print(f\"[System] í˜„ì¬ ëª¨ë“œ: {current_mode.upper()}\")\n",
    "    print(f\"[AI]: {engine.session_manager.get_welcome_message(user_id)}\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # ì‚¬ìš©ì ì…ë ¥ ì‹œ í˜„ì¬ ëª¨ë“œë¥¼ í”„ë¡¬í”„íŠ¸ì— í‘œì‹œ\n",
    "            mode_indicator = \"ğŸ’¬ê°ì„±ëŒ€í™”\" if current_mode == \"chat\" else \"â„¹ï¸ì •ë³´ì œê³µ\"\n",
    "            user_input = input(f\"[{mode_indicator} | ë‚˜]: \").strip()\n",
    "\n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "            # í† ê¸€ ëª…ë ¹ì–´ ì²˜ë¦¬ (UIì˜ ë²„íŠ¼ í´ë¦­ ì‹œë®¬ë ˆì´ì…˜)\n",
    "            if user_input == \"/toggle\":\n",
    "                if current_mode == \"chat\":\n",
    "                    current_mode = \"info\"\n",
    "                else:\n",
    "                    current_mode = \"chat\"\n",
    "                print(f\"\\n>>> ğŸ”„ ëª¨ë“œë¥¼ [{current_mode.upper()}]ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\\n\")\n",
    "                continue\n",
    "\n",
    "            # ì—”ì§„ í˜¸ì¶œ (í˜„ì¬ ëª¨ë“œë¥¼ ì¸ìë¡œ ì „ë‹¬)\n",
    "            response = engine.process_user_message(user_id, user_input, mode=current_mode)\n",
    "            \n",
    "            print(f\"[{mode_indicator} | AI]: {response}\\n\")\n",
    "\n",
    "            if user_input == \"ê·¸ë§Œ\":\n",
    "                print(\">>> í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975c0130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [í…ŒìŠ¤íŠ¸] ì›°ë‹¤ì‰ ì±—ë´‡ ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸\n",
      ">>> '/toggle'ì„ ì…ë ¥í•˜ë©´ ì±„íŒ… ëª¨ë“œì™€ ì •ë³´ ëª¨ë“œê°€ ì „í™˜ë©ë‹ˆë‹¤.\n",
      ">>> 'ê·¸ë§Œ'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.\n",
      "\n",
      "[System] í˜„ì¬ ëª¨ë“œ: CHAT\n",
      "[AI]: ë‹¤ì‹œ ì˜¤ì…¨êµ°ìš”. ì´ì•¼ê¸°ë¥¼ ê³„ì† ë‚˜ëˆ ë³¼ê¹Œìš”?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:conversation_engine:[Router] Current Mode: chat\n",
      "INFO:chatbot_modules.empathy_agent:>>> [Agent Active] Empathy Agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ğŸ’¬ê°ì„±ëŒ€í™” | AI]: ë§ì´ í˜ë“œì…¨ê² ì–´ìš”. ë¬´ê¸°ë ¥í•¨ì´ ê³„ì†ë˜ë©´ ë§ˆìŒì´ ì§€ì¹˜ê¸° ë§ˆë ¨ì´ì£ . í˜¹ì‹œ ê´œì°®ìœ¼ì‹œë‹¤ë©´, ì‘ì€ í™œë™ì´ë‚˜ ê¸°ë¶„ ì „í™˜ì„ ìœ„í•œ ë°©ë²•ì„ ì°¾ì•„ë³¼ê¹Œìš”? ë¬¼ë¡ , ì§€ê¸ˆì²˜ëŸ¼ ì´ì•¼ê¸°ë¥¼ ì´ì–´ê°€ë„ ê´œì°®ì•„ìš”.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:conversation_engine:[Router] Current Mode: chat\n",
      "INFO:chatbot_modules.empathy_agent:>>> [Agent Active] Empathy Agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:chatbot_modules.empathy_agent:>>> [Agent Active] Empathy Agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool ì§ˆë¬¸]\n",
      " ['- ìš”ì¦˜ í¸ì•ˆí•¨ì„ ëŠë¼ëŠ” ì¥ì†Œê°€ ìˆë‚˜ìš”? (ì˜ë„: light)', '- ìŠ¤ìŠ¤ë¡œ ê°€ì¥ ìš©ê¸°ëƒˆë‹¤ê³  ëŠë¼ëŠ” ìˆœê°„ì´ ìˆë‚˜ìš”? (ì˜ë„: deep)', '- ì˜¤ëŠ˜ ë§ˆìŒì´ ì¡°ê¸ˆ ê°€ë²¼ì›Œì§„ ìˆœê°„ì´ ìˆì—ˆë‚˜ìš”? (ì˜ë„: light)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ğŸ’¬ê°ì„±ëŒ€í™” | AI]: ìŠ¤ìŠ¤ë¡œ ê°€ì¥ ìš©ê¸°ëƒˆë‹¤ê³  ëŠë¼ëŠ” ìˆœê°„ì´ ìˆë‚˜ìš”? ê·¸ëŸ° ìˆœê°„ë“¤ì´ ë•Œë•Œë¡œ ìš°ë¦¬ì—ê²Œ í˜ì´ ë˜ê¸°ë„ í•˜ì£ .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:conversation_engine:[Router] Current Mode: chat\n",
      "INFO:chatbot_modules.empathy_agent:>>> [Agent Active] Empathy Agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ğŸ’¬ê°ì„±ëŒ€í™” | AI]: ì•Œê² ìŠµë‹ˆë‹¤. ì–¸ì œë“ ì§€ í•„ìš”í•˜ì‹¤ ë•Œ ë‹¤ì‹œ ì´ì•¼ê¸° ë‚˜ëˆ„ì–´ìš”. ì˜¤ëŠ˜ í•˜ë£¨ ì˜ ë§ˆë¬´ë¦¬í•˜ì‹œê¸¸ ë°”ë„ê²Œìš”.\n",
      "\n",
      "[ì‹œìŠ¤í…œ]: ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ë©° ì˜¤ëŠ˜ì˜ ë‹¤ì´ì–´ë¦¬ë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ì˜¤ëŠ˜ì˜ ë‹¤ì´ì–´ë¦¬**\n",
      "\n",
      "ì˜¤ëŠ˜ì€ ë§ˆìŒì´ ë¬´ê²ê³  ë³µì¡í•œ í•˜ë£¨ì˜€ë‹¤. ì™¸ë¡œì›€ ì†ì—ì„œ ìƒˆë¡œìš´ ì¸ì—°ì„ ë§Œë“¤ê³  ì‹¶ì—ˆì§€ë§Œ, ë§ˆìŒì˜ ì§ì´ ì—¬ì „íˆ í¬ê²Œ ë‹¤ê°€ì™”ë‹¤. ì§œì¥ë©´ì„ ë¨¹ìœ¼ë©° ì ì‹œë‚˜ë§ˆ ê¸°ë¶„ ì „í™˜ì„ í–ˆì§€ë§Œ, ë¬´ê¸°ë ¥í•¨ì´ ê³„ì†í•´ì„œ ë‚˜ë¥¼ ê´´ë¡­í˜”ë‹¤. ê·¸ë˜ë„ ìŠ¤ìŠ¤ë¡œì˜ ê°ì •ì„ ì†”ì§íˆ ë°”ë¼ë³´ê³ , ì‘ì€ í™œë™ìœ¼ë¡œ ì¡°ê¸ˆì”© ìœ„ì•ˆì„ ì°¾ì•„ê°€ë ¤ëŠ” ë…¸ë ¥ì„ ë©ˆì¶”ì§€ ì•Šì•˜ë‹¤. ì˜¤ëŠ˜ì€ ë‚´ ë§ˆìŒì„ ëŒë³´ëŠ” ê²ƒì´ ë¬´ì—‡ë³´ë‹¤ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë‹¤ì‹œ ëŠë‚€ ë‚ ì´ì—ˆë‹¤.\n",
      "\n",
      ">>> í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29273323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mermaid.live/\n",
      "\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tempathy_agent(empathy_agent)\n",
      "\tinfo_agent(info_agent)\n",
      "\ttools(tools)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ -.-> empathy_agent;\n",
      "\t__start__ -.-> info_agent;\n",
      "\tempathy_agent -.-> __end__;\n",
      "\tempathy_agent -.-> tools;\n",
      "\ttools --> empathy_agent;\n",
      "\tinfo_agent --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from conversation_engine import ConversationEngine\n",
    "\n",
    "def visualize_langgraph():\n",
    "    # 1. ì—”ì§„ ì´ˆê¸°í™” (ê·¸ë˜í”„ ë¹Œë“œ)\n",
    "    engine = ConversationEngine()\n",
    "    \n",
    "    # 2. ì»´íŒŒì¼ëœ LangGraph ì•± ê°ì²´ ê°€ì ¸ì˜¤ê¸°\n",
    "    app = engine.app\n",
    "    \n",
    "    # 3. Mermaid ë¬¸ë²•ìœ¼ë¡œ ì¶œë ¥ (í„°ë¯¸ë„ìš©)\n",
    "    print(\"https://mermaid.live/\")\n",
    "    print()\n",
    "    \n",
    "    mermaid_code = app.get_graph().draw_mermaid()\n",
    "    print(mermaid_code)\n",
    "    \n",
    "visualize_langgraph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
